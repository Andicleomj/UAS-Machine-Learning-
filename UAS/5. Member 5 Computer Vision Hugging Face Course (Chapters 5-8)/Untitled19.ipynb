{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "5. Member 5: Computer Vision Hugging Face Course (Chapters 5-8)\n",
        "Reproduce the code from Chapters 5-8 of the Computer Vision Hugging Face Course.\n",
        "Create a detailed video tutorial explaining these chapters.\n",
        "Cover key concepts and challenges."
      ],
      "metadata": {
        "id": "Zd-vECtGzR9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNIT 5"
      ],
      "metadata": {
        "id": "_k1nl0wXzakM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install torch torchvision matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDYrFogZze78",
        "outputId": "388d5316-a6e6-43a2-858e-ce6e1bf0192e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qOyfU32Azg7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "mnist_data = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "data_loader = DataLoader(mnist_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "gP2LioO4zkSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the VAE model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim=784, hidden_dim=256, latent_dim=64):\n",
        "        super(VAE, self).__init__()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.mu_layer = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.logvar_layer = nn.Linear(hidden_dim, latent_dim)\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        mu = self.mu_layer(encoded)\n",
        "        logvar = self.logvar_layer(encoded)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar"
      ],
      "metadata": {
        "id": "bs2WU0ktznIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "def vae_loss(reconstructed, original, mu, logvar):\n",
        "    BCE = nn.functional.binary_cross_entropy(reconstructed, original, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD"
      ],
      "metadata": {
        "id": "folw4ND-zooc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, optimizer, and train\n",
        "vae = VAE()\n",
        "optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
        "\n",
        "epochs = 5\n",
        "vae.train()\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss = 0\n",
        "    for batch, _ in data_loader:\n",
        "        batch = batch.view(-1, 784)\n",
        "        optimizer.zero_grad()\n",
        "        reconstructed, mu, logvar = vae(batch)\n",
        "        loss = vae_loss(reconstructed, batch, mu, logvar)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(data_loader.dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwDcq34kzqkm",
        "outputId": "75d6d2c6-a1a3-4687-c5c7-156f3853af64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 161.947768351237\n",
            "Epoch 2, Loss: 125.13386153564453\n",
            "Epoch 3, Loss: 115.9360458577474\n",
            "Epoch 4, Loss: 112.26203598632813\n",
            "Epoch 5, Loss: 110.41916883951824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize reconstructed images\n",
        "vae.eval()\n",
        "with torch.no_grad():\n",
        "    batch, _ = next(iter(data_loader))\n",
        "    batch = batch.view(-1, 784)\n",
        "    reconstructed, _, _ = vae(batch)\n",
        "    fig, axes = plt.subplots(1, 10, figsize=(15, 3))\n",
        "    for i in range(10):\n",
        "        axes[i].imshow(reconstructed[i].view(28, 28).cpu().numpy(), cmap='gray')\n",
        "        axes[i].axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "7Xpc_MuWzt-h",
        "outputId": "7267607b-03db-46ef-853f-8561469a9895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chapter 6: Basic Computer Vision Tasks"
      ],
      "metadata": {
        "id": "9H_LZlkYz7xZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Hugging Face libraries\n",
        "!pip install transformers\n",
        "\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "from PIL import Image\n",
        "import requests\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alcljcYOz_IA",
        "outputId": "a34cf15e-2f0e-49aa-8146-a567b0ac1ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained model and processor\n",
        "model_name = \"google/vit-base-patch16-224\"\n",
        "processor = AutoImageProcessor.from_pretrained(model_name)\n",
        "model = AutoModelForImageClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGKhSs1105oC",
        "outputId": "3fee8790-5379-4491-d28d-849e36c56f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ganti dengan URL gambar yang benar\n",
        "url = \"https://datasets-server.huggingface.co/assets/coco/--/coco/train/000000000009.jpg\"\n",
        "response = requests.get(url)"
      ],
      "metadata": {
        "id": "o9g2tFpi07SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Periksa apakah respons berhasil\n",
        "if response.status_code == 200:\n",
        "    # Baca gambar dari bytes\n",
        "    image = Image.open(BytesIO(response.content))\n",
        "    image.show()  # Menampilkan gambar\n",
        "else:\n",
        "    print(f\"Failed to fetch image. Status code: {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKR4Nh8J09T9",
        "outputId": "82d6d18c-a070-48ec-ba6f-7f6234f18052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch image. Status code: 403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chapter 7: Video and Video Processing"
      ],
      "metadata": {
        "id": "Sb1td-Rd1aXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "kKZsl6FD1b1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load video file\n",
        "video_path = \"example.mp4\"  # Replace with your video file path\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    # Convert to grayscale\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    cv2.imshow(\"Gray Frame\", gray_frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "H0lrRmMz1deI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chapter 8: 3D Vision, Scene Rendering, and Reconstruction"
      ],
      "metadata": {
        "id": "7gSKGO1u1hs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "!pip install pytorch3d==0.7.1  # Install PyTorch3D versi 0.7.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zat1lPkz1kFB",
        "outputId": "3cceb318-03af-4c00-ca11-1fcc475e16a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch3d==0.7.1 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch3d==0.7.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pytorch3d.io import load_objs_as_meshes_from_path\n",
        "from pytorch3d.renderer import (\n",
        "    PerspectiveCameras, RasterizationSettings, MeshRenderer,\n",
        "    MeshRasterizer, SoftPhongShader, PointLights\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "9ZZFYaON10o9",
        "outputId": "b8dd3841-9ab8-46b6-a62b-56cca8084af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pytorch3d'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3783dd530a4d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_objs_as_meshes_from_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m from pytorch3d.renderer import (\n\u001b[1;32m      4\u001b[0m     \u001b[0mPerspectiveCameras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRasterizationSettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMeshRenderer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mMeshRasterizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSoftPhongShader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPointLights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch3d'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load 3D mesh\n",
        "obj_path = \"path/to/3d_model.obj\"  # Replace with your .obj file\n",
        "mesh = load_objs_as_meshes([obj_path])\n"
      ],
      "metadata": {
        "id": "qPXkYqBT1lzg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "542fb039-961a-4660-e7a7-388d29f4b227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'load_objs_as_meshes' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2581f5f8c783>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load 3D mesh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mobj_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"path/to/3d_model.obj\"\u001b[0m  \u001b[0;31m# Replace with your .obj file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_objs_as_meshes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'load_objs_as_meshes' is not defined"
          ]
        }
      ]
    }
  ]
}